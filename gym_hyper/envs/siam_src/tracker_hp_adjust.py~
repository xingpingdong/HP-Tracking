import tensorflow as tf
print('Using Tensorflow '+tf.__version__)
import matplotlib.pyplot as plt
import sys
# sys.path.append('../')
import os
import csv
import numpy as np
from PIL import Image
import time
import siamese0 as siam
from visualization import show_frame, show_crops, show_scores


gpu_device = 0
os.environ['CUDA_VISIBLE_DEVICES'] = '{}'.format(gpu_device)

# read default parameters and override with custom ones
def tracker(hp, run, design, frame_name_list, pos_x, pos_y, target_w, target_h, final_score_sz, filename, image, templates_z, scores, start_frame, mu_model, env, score_low):
    num_frames = np.size(frame_name_list)
    # stores tracker's output for evaluation
    bboxes = np.zeros((num_frames,4))

    scale_factors = hp.scale_step**np.linspace(-np.ceil(hp.scale_num/2), np.ceil(hp.scale_num/2), hp.scale_num)
    # cosine window to penalize large displacements    
    hann_1d = np.expand_dims(np.hanning(final_score_sz), axis=0)
    penalty = np.transpose(hann_1d) * hann_1d
    penalty = penalty / np.sum(penalty)

    context = design.context*(target_w+target_h)
    z_sz = np.sqrt(np.prod((target_w+context)*(target_h+context)))
    x_sz = float(design.search_sz) / design.exemplar_sz * z_sz

    # thresholds to saturate patches shrinking/growing
    min_z = hp.scale_min * z_sz
    max_z = hp.scale_max * z_sz
    min_x = hp.scale_min * x_sz
    max_x = hp.scale_max * x_sz

    # run_metadata = tf.RunMetadata()
    # run_opts = {
    #     'options': tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),
    #     'run_metadata': run_metadata,
    # }

    run_opts = {}
    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)
    # with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:
    sess0 = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))
    # with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
    #with tf.Session() as sess:
    with sess0.as_default():
        tf.global_variables_initializer().run()
        # Coordinate the loading of image files.
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)
    sess = tf.Session()
    tf.global_variables_initializer().run(session=sess)
    coord = tf.train.Coordinator()
    # save first frame position (from ground-truth)
    bboxes[0,:] = pos_x-target_w/2, pos_y-target_h/2, target_w, target_h

    image_, templates_z_ = sess.run([image, templates_z], feed_dict={
                                                                    siam.pos_x_ph: pos_x,
                                                                    siam.pos_y_ph: pos_y,
                                                                    siam.z_sz_ph: z_sz,
                                                                    filename: frame_name_list[0]})
    new_templates_z_ = templates_z_

    scaled_search_area = x_sz * scale_factors
    image_,  score_low_ = sess.run(
                [image,  score_low],
                feed_dict={
                    siam.pos_x_ph: pos_x,
                    siam.pos_y_ph: pos_y,
                    siam.x_sz0_ph: scaled_search_area[0],
                    siam.x_sz1_ph: scaled_search_area[1],
                    siam.x_sz2_ph: scaled_search_area[2],
                    templates_z: np.squeeze(templates_z_),
                    filename: frame_name_list[1],
                }, **run_opts)
    score_low_ = np.squeeze(score_low_)

    # u = mu_model.predict(np.reshape(scores_,(1,1)+scores_.shape))
    # u = np.clip(u, env.min_range, env.max_range)[0]
    # u = u * env.scale_range + env.low_hp
    # hp._replace(scale_step=u[0], scale_penalty=u[1], scale_lr=u[2], window_influence=u[3], z_lr=u[4])
    # scale_factors = hp.scale_step**np.linspace(-np.ceil(hp.scale_num/2), np.ceil(hp.scale_num/2), hp.scale_num)

    t_start = time.time()

    # Get an image from the queue
    for i in range(1, num_frames):
        # adjust hyperparameter
        u = mu_model.predict(np.reshape(score_low_[1,:,:],(1,1,score_low_.shape[1],score_low_.shape[2])))
        if i==1:
            u0 = u
            s0 = score_low_[1,:,:]
            print "i = "+ str(i) +"  u = " + str(u)
        if np.sum(np.abs(u-u0)) < 0.001:
            u0 = u
            print "i = "+ str(i) +"  u = " + str(u)
        u = np.clip(u, env.min_range, env.max_range)[0]
        u = u * env.scale_range + env.low_hp

        # d_s = np.sum(np.abs(s0-score_low_[1,:,:]))
        # if d_s > 0.001:
        #     print "i = "+ str(i) +' d_s = {}'.format(d_s)
        # u[1]=0.9
        # u[0] = 1.005
        hp = hp._replace(scale_step=u[0], scale_penalty=u[1], scale_lr=u[2], window_influence=u[3], z_lr=u[4])
        scale_factors = hp.scale_step**np.linspace(-np.ceil(hp.scale_num/2), np.ceil(hp.scale_num/2), hp.scale_num)

        scaled_exemplar = z_sz * scale_factors
        scaled_search_area = x_sz * scale_factors
        # scaled_search_area[0] = np.floor(scaled_search_area[0])
        # scaled_search_area[1] = np.floor(scaled_search_area[1])
        # scaled_search_area[2] = np.ceil(scaled_search_area[2])
        scaled_target_w = target_w * scale_factors
        scaled_target_h = target_h * scale_factors
        # print "scaled_search_area: ",scaled_search_area
        try:
            image_, scores_, score_low_ = sess.run(
                [image, scores, score_low],
                feed_dict={
                    siam.pos_x_ph: pos_x,
                    siam.pos_y_ph: pos_y,
                    siam.x_sz0_ph: scaled_search_area[0],
                    siam.x_sz1_ph: scaled_search_area[1],
                    siam.x_sz2_ph: scaled_search_area[2],
                    templates_z: np.squeeze(templates_z_),
                    filename: frame_name_list[i],
                }, **run_opts)
        except BaseException,info:
            print(info)
            print "u is :" , u
            print "z_sz and scale_factors: ", z_sz, scale_factors
            print "scaled_search_area: ",scaled_search_area
            print "i is:", i
        scores_ = np.squeeze(scores_)
        # penalize change of scale
        scores_[0,:,:] = hp.scale_penalty*scores_[0,:,:]
        scores_[2,:,:] = hp.scale_penalty*scores_[2,:,:]
        # find scale with highest peak (after penalty)
        new_scale_id = np.argmax(np.amax(scores_, axis=(1,2)))
        # update scaled sizes
        x_sz = (1-hp.scale_lr)*x_sz + hp.scale_lr*scaled_search_area[new_scale_id]
        x_sz = max(min_x,x_sz)
        x_sz = min(max_x,x_sz)
        target_w = (1-hp.scale_lr)*target_w + hp.scale_lr*scaled_target_w[new_scale_id]
        target_h = (1-hp.scale_lr)*target_h + hp.scale_lr*scaled_target_h[new_scale_id]
        # select response with new_scale_id
        score_ = scores_[new_scale_id,:,:]
        score_ = score_ - np.min(score_)
        score_ = score_/np.sum(score_)
        # apply displacement penalty
        score_ = (1-hp.window_influence)*score_ + hp.window_influence*penalty
        pos_x, pos_y = _update_target_position(pos_x, pos_y, score_, final_score_sz, design.tot_stride, design.search_sz, hp.response_up, x_sz)
        # convert <cx,cy,w,h> to <x,y,w,h> and save output
        bboxes[i,:] = pos_x-target_w/2, pos_y-target_h/2, target_w, target_h
        # update the target representation with a rolling average
        if hp.z_lr>0:
            new_templates_z_ = sess.run([templates_z], feed_dict={
                                                            siam.pos_x_ph: pos_x,
                                                            siam.pos_y_ph: pos_y,
                                                            siam.z_sz_ph: z_sz,
                                                            image: image_
                                                            })

            templates_z_=(1-hp.z_lr)*np.asarray(templates_z_) + hp.z_lr*np.asarray(new_templates_z_)

        # update template patch size
        z_sz = (1-hp.scale_lr)*z_sz + hp.scale_lr*scaled_exemplar[new_scale_id]
        z_sz = max(min_z,z_sz)
        z_sz = min(max_z,z_sz)

        if run.visualization:
            show_frame(image_, bboxes[i,:], 1)

        if i%1000==999:
            sess.close()
            sess = tf.Session()
            with sess.as_default():
                tf.global_variables_initializer().run()
                # Coordinate the loading of image files.
                coord = tf.train.Coordinator()
                threads = tf.train.start_queue_runners(coord=coord)

    sess.close()

    t_elapsed = time.time() - t_start
    speed = num_frames/t_elapsed

    # Finish off the filename queue coordinator.
    coord.request_stop()
    coord.join(threads)

        # from tensorflow.python.client import timeline
        # trace = timeline.Timeline(step_stats=run_metadata.step_stats)
        # trace_file = open('timeline-search.ctf.json', 'w')
        # trace_file.write(trace.generate_chrome_trace_format())

    plt.close('all')

    return bboxes, speed


def _update_target_position(pos_x, pos_y, score, final_score_sz, tot_stride, search_sz, response_up, x_sz):
    # find location of score maximizer
    p = np.asarray(np.unravel_index(np.argmax(score), np.shape(score)))
    # displacement from the center in search area final representation ...
    center = float(final_score_sz - 1) / 2
    disp_in_area = p - center
    # displacement from the center in instance crop
    disp_in_xcrop = disp_in_area * float(tot_stride) / response_up
    # displacement from the center in instance crop (in frame coordinates)
    disp_in_frame = disp_in_xcrop *  x_sz / search_sz
    # *position* within frame in frame coordinates
    pos_y, pos_x = pos_y + disp_in_frame[0], pos_x + disp_in_frame[1]
    return pos_x, pos_y


